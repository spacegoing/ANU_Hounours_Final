\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Tsochantaridis:ICML04,Taskar:ICML05}
\citation{Koller:2009}
\citation{Finley:ICML08}
\citation{Rother:CVPR09,Nowozin:CVPR09,Lempitsky:ICCV09}
\citation{Kohli:CVPR10}
\citation{Kohli:CVPR07}
\citation{Rother:SIGGRAPH04}
\citation{Borenstein:ECCV02}
\citation{Kohli:CVPR10}
\citation{Kohli:CVPR10}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\newlabel{sec:intro}{{1}{1}{Introduction}{section.1}{}}
\citation{Kohli:CVPR07}
\citation{Kohli:TR08}
\citation{Boykov:ICCV99,Boykov:PAMI04}
\citation{Ladicky:ICCV09}
\citation{PASCAL:VOC:2012}
\citation{Carreira:ECCV12}
\citation{Gould:ICML2011}
\citation{Ishikawa:PAMI03,Ishikawa:CVPR09,Rother:CVPR09}
\citation{Boros:MATH02}
\citation{Hammer:1965,Freedman:CVPR05}
\citation{Orlin:MP2009}
\citation{Kolmogorov:DAM12}
\citation{Boykov:PAMI04}
\citation{Tsochantaridis:ICML04,Tsochantaridis:JMLR05}
\citation{Taskar:ICML05}
\citation{Joachims:ML09}
\citation{Szummer:ECCV08}
\citation{Nowozin:2011,Lempitsky:ICCV09,Kohli:CVPR07}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{2}{section.2}}
\newlabel{sec:background}{{2}{2}{Related Work}{section.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Lower Linear Envelope MRFs}{2}{section.3}}
\newlabel{sec:inference}{{3}{2}{Lower Linear Envelope MRFs}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Higher-order MRFs}{2}{subsection.3.1}}
\newlabel{eqn:energy}{{1}{2}{Higher-order MRFs}{equation.3.1}{}}
\newlabel{eqn:potential}{{2}{2}{Higher-order MRFs}{equation.3.2}{}}
\citation{Gould:ICML2011}
\citation{Kohli:CVPR10}
\citation{Kolmogorov:DAM12,Orlin:MP2009}
\citation{Freedman:CVPR05,Ishikawa:CVPR09,Boros:MATH02}
\citation{Kohli:TR08}
\citation{Gould:ICML2011}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces  Example lower linear envelope $\psi ^H_c\tmspace  -\thinmuskip {.1667em}({\boldsymbol  {y}}_c)$ (shown solid) with three terms (dashed) as a function of $W_{\tmspace  -\thinmuskip {.1667em}c}({\boldsymbol  {y}}_c) = \DOTSB \sum@ \slimits@ _{i \in c} w^c_i y_i$. When $W_{\tmspace  -\thinmuskip {.1667em}c}({\boldsymbol  {y}}_c) \leq W_1$ the first linear function is active, when $W_1 < W_{\tmspace  -\thinmuskip {.1667em}c}({\boldsymbol  {y}}_c) \leq W_2$ the second linear function is active, otherwise the third linear function is active.\relax }}{3}{figure.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:nonredundant}{{1}{3}{Example lower linear envelope $\psi ^H_c\!(\by _c)$ (shown solid) with three terms (dashed) as a function of $W_{\!c}(\by _c) = \sum _{i \in c} w^c_i y_i$. When $W_{\!c}(\by _c) \leq W_1$ the first linear function is active, when $W_1 < W_{\!c}(\by _c) \leq W_2$ the second linear function is active, otherwise the third linear function is active.\relax }{figure.caption.1}{}}
\newlabel{eqn:potential2}{{3}{3}{Higher-order MRFs}{equation.3.3}{}}
\newlabel{prop:condition}{{3.1}{3}{}{THEOREM.3.1}{}}
\newlabel{obs:b0}{{3.2}{3}{}{THEOREM.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Exact Inference}{3}{subsection.3.2}}
\newlabel{sec:exact_inference}{{3.2}{3}{Exact Inference}{subsection.3.2}{}}
\citation{Gould:ICML2011}
\citation{Boros:MATH02}
\citation{Boros:MATH02}
\citation{Kolmogorov:PAMI04,Hammer:1965}
\citation{Kolmogorov:PAMI04}
\citation{Kolmogorov:PAMI04}
\newlabel{eqn:binary_concave_z}{{6}{4}{Exact Inference}{equation.3.6}{}}
\newlabel{prop:minpsi}{{3.3}{4}{}{THEOREM.3.3}{}}
\newlabel{lem:noconstraints}{{3.4}{4}{}{THEOREM.3.4}{}}
\newlabel{eqn:posiform}{{7}{4}{Exact Inference}{equation.3.7}{}}
\newlabel{prop:submod}{{3.7}{4}{}{THEOREM.3.7}{}}
\newlabel{thm:inference}{{3.8}{4}{}{THEOREM.3.8}{}}
\citation{Tsochantaridis:ICML04}
\citation{Taskar:ICML05}
\citation{Pletscher:AISTATS12}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces  Construction of an $st$-graph for minimizing energy functions with arbitrary weighted lower linear envelope potentials. Every cut corresponds to an assignment to the random variables, where variables associated with nodes in the ${\cal  S}$ set take the value one, and those associated with nodes in the ${\cal  T}$ set take the value zero. With slight abuse of notation, we use the variables to denote nodes in our graph. For each lower linear envelope potential edges are added as follows: for each $i \in c$, add an edge from $y_i$ to $t$ with weight $a_1 w^c_i$; for each $i \in c$ and $k = 1, \ldots  , K-1$, add an edge from $z_k$ to $y_i$ with weight $(a_{k} - a_{k+1}) w^c_i$; and for $k = 1, \ldots  , K-1$, add an edge from $s$ to $z_k$ with weight $a_k - a_{k+1}$ and edge from $z_k$ to $t$ with weight $b_{k+1} - b_k$. Other edges may be required to represent unary and pairwise potentials (see \citep  {Kolmogorov:PAMI04}). \relax }}{5}{figure.caption.2}}
\newlabel{fig:stmincut}{{2}{5}{Construction of an $st$-graph for minimizing energy functions with arbitrary weighted lower linear envelope potentials. Every cut corresponds to an assignment to the random variables, where variables associated with nodes in the ${\cal S}$ set take the value one, and those associated with nodes in the $\T $ set take the value zero. With slight abuse of notation, we use the variables to denote nodes in our graph. For each lower linear envelope potential edges are added as follows: for each $i \in c$, add an edge from $y_i$ to $t$ with weight $a_1 w^c_i$; for each $i \in c$ and $k = 1, \ldots , K-1$, add an edge from $z_k$ to $y_i$ with weight $(a_{k} - a_{k+1}) w^c_i$; and for $k = 1, \ldots , K-1$, add an edge from $s$ to $z_k$ with weight $a_k - a_{k+1}$ and edge from $z_k$ to $t$ with weight $b_{k+1} - b_k$. Other edges may be required to represent unary and pairwise potentials (see \cite {Kolmogorov:PAMI04}). \relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Relationship to Binary MRFs}{5}{subsection.3.3}}
\newlabel{eqn:energy_z}{{8}{5}{Relationship to Binary MRFs}{equation.3.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Learning the Lower Linear Envelope}{5}{section.4}}
\newlabel{sec:learning}{{4}{5}{Learning the Lower Linear Envelope}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Max-margin Learning}{5}{subsection.4.1}}
\newlabel{eqn:maxmarginqp}{{9}{5}{Max-margin Learning}{equation.4.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces  Example piecewise-linear concave function of $W_{\tmspace  -\thinmuskip {.1667em}c}({\boldsymbol  {y}}_c) = \DOTSB \sum@ \slimits@ _{i \in c} w^c_i y_i$. The function can be represented as the minimum over a set of linear functions (lower linear envelope) or as a set of sampled points $\theta _k$ with curvature constraint.\relax }}{6}{figure.caption.3}}
\newlabel{fig:concave}{{3}{6}{Example piecewise-linear concave function of $W_{\!c}(\by _c) = \sum _{i \in c} w^c_i y_i$. The function can be represented as the minimum over a set of linear functions (lower linear envelope) or as a set of sampled points $\theta _k$ with curvature constraint.\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Transforming Between Representations}{6}{subsection.4.2}}
\newlabel{sec:representation_transformation}{{4.2}{6}{Transforming Between Representations}{subsection.4.2}{}}
\newlabel{eqn:features}{{12}{6}{Transforming Between Representations}{equation.4.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces  Illustration of how the feature vector $\phi ({\boldsymbol  {y}})$ interpolates between samples to produce the correct value for the active linear function.\relax }}{6}{figure.caption.4}}
\newlabel{fig:features}{{4}{6}{Illustration of how the feature vector $\phi (\by )$ interpolates between samples to produce the correct value for the active linear function.\relax }{figure.caption.4}{}}
\citation{Tsochantaridis:JMLR05}
\citation{Yu:ICML09}
\newlabel{alg:learning}{{1}{7}{Learning lower linear envelope MRFs.\relax }{algorithm.1}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces  Learning lower linear envelope MRFs.\relax }}{7}{algorithm.1}}
\newlabel{thm:learning}{{4.1}{7}{}{THEOREM.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Alternative QP Formulations}{7}{subsection.4.3}}
\newlabel{sec:alternative_qp}{{4.3}{7}{Alternative QP Formulations}{subsection.4.3}{}}
\newlabel{eqn:bk}{{16}{7}{Alternative QP Formulations}{equation.4.16}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Experimental Results}{7}{section.5}}
\newlabel{sec:experiments}{{5}{7}{Experimental Results}{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Synthetic Checkerboard}{7}{subsection.5.1}}
\citation{Rother:SIGGRAPH04}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces  Inferred output from our synthetic experiments. Shown are (a) the ground-truth labels, (b) noisy inputs, (c) best inferred labels using a pairwise model, (d)-(e) inferred output from the model containing higher-order terms after three training iterations and at convergence, respectively. Matlab source code for reproducing these results is available from the author's homepage.\relax }}{8}{figure.caption.5}}
\newlabel{fig:synthetic_results}{{5}{8}{Inferred output from our synthetic experiments. Shown are (a) the ground-truth labels, (b) noisy inputs, (c) best inferred labels using a pairwise model, (d)-(e) inferred output from the model containing higher-order terms after three training iterations and at convergence, respectively. Matlab source code for reproducing these results is available from the author's homepage.\relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Interactive Figure-Ground Segmentation}{8}{subsection.5.2}}
\citation{Lempitsky:ICCV09}
\citation{Rother:SIGGRAPH04}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces  Learned linear envelopes (parameters are normalized by the unary weight) for synthetic experiments. The first row (a)-(c) shows results with symmetric noise ($\eta _0 = \eta _1 = 0.1$) while the second row (d)-(f) shows results with asymmetric noise ($\eta _0 = 0.5$ and $\eta _1 = 0.1$). Compared are models with unary and higher-order potentials with $K = 10$ linear terms ((a) and (d)), unary, pairwise and higher-order potentials ((b) and (e)), and unary and higher-order potentials with $K = 50$ linear terms ((c) and (f)).\relax }}{9}{figure.caption.6}}
\newlabel{fig:synthetic_weights}{{6}{9}{Learned linear envelopes (parameters are normalized by the unary weight) for synthetic experiments. The first row (a)-(c) shows results with symmetric noise ($\eta _0 = \eta _1 = 0.1$) while the second row (d)-(f) shows results with asymmetric noise ($\eta _0 = 0.5$ and $\eta _1 = 0.1$). Compared are models with unary and higher-order potentials with $K = 10$ linear terms ((a) and (d)), unary, pairwise and higher-order potentials ((b) and (e)), and unary and higher-order potentials with $K = 50$ linear terms ((c) and (f)).\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces  Inferred output from our synthetic experiments with misspecified cliques. Shown are inferred outputs from the model at convergence. Rows (i)--(ii) correspond to partially covering each grid square with 1, 2 and 5 higher-order cliques, respectively. Columns (a)-(d) correspond to the size of each clique (95\%, 90\%, 75\%, 50\% grid square coverage, respectively). In addition, 10\% of the cliques were generated to contain random a random mix of pixels.\relax }}{9}{figure.caption.7}}
\newlabel{fig:synth_corrupt_results}{{7}{9}{Inferred output from our synthetic experiments with misspecified cliques. Shown are inferred outputs from the model at convergence. Rows (i)--(ii) correspond to partially covering each grid square with 1, 2 and 5 higher-order cliques, respectively. Columns (a)-(d) correspond to the size of each clique (95\%, 90\%, 75\%, 50\% grid square coverage, respectively). In addition, 10\% of the cliques were generated to contain random a random mix of pixels.\relax }{figure.caption.7}{}}
\citation{Ladicky:ICCV09}
\citation{Comaniciu:PAMI02}
\citation{Borenstein:ECCV02,Borenstein:CVPR04}
\citation{Shotton:ECCV06}
\citation{Comaniciu:PAMI02}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces  Example results from our GrabCut experiments. Shown are: (a) the image and bounding box, (b) ground-truth segmentation, (c) baseline model output, and (d) output from model with higher-order terms.\relax }}{10}{figure.caption.8}}
\newlabel{fig:grabcut_results}{{8}{10}{Example results from our GrabCut experiments. Shown are: (a) the image and bounding box, (b) ground-truth segmentation, (c) baseline model output, and (d) output from model with higher-order terms.\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Weizmann Horses}{10}{subsection.5.3}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces  Results from our Weizmann Horse experiments. The baseline model includes unary and pairwise terms. The higher-order model includes unary, pairwise and lower-linear envelope terms defined by multiple over-segmentations. See text for details.\relax }}{10}{table.caption.9}}
\newlabel{tab:weizmann_results}{{1}{10}{Results from our Weizmann Horse experiments. The baseline model includes unary and pairwise terms. The higher-order model includes unary, pairwise and lower-linear envelope terms defined by multiple over-segmentations. See text for details.\relax }{table.caption.9}{}}
\citation{Park:ECCV2012}
\citation{Boykov:ICCV99}
\citation{Kohli:PAMI07}
\citation{Komodakis:CVPR2011}
\citation{Nowozin:2011,Bertsekas:2004}
\citation{Yu:ICML09}
\bibstyle{abbrvnat}
\bibdata{long,scene}
\bibcite{Bertsekas:2004}{{1}{2004}{{Bertsekas}}{{}}}
\bibcite{Borenstein:ECCV02}{{2}{2002}{{Borenstein and Ullman}}{{}}}
\bibcite{Borenstein:CVPR04}{{3}{2004}{{Borenstein et~al.}}{{Borenstein, Sharon, and Ullman}}}
\bibcite{Boros:MATH02}{{4}{2002}{{Boros and Hammer}}{{}}}
\bibcite{Boykov:PAMI04}{{5}{2004}{{Boykov and Kolmogorov}}{{}}}
\bibcite{Boykov:ICCV99}{{6}{1999}{{Boykov et~al.}}{{Boykov, Veksler, and Zabih}}}
\bibcite{Carreira:ECCV12}{{7}{2012}{{Carreira et~al.}}{{Carreira, Caseiro, Batista, and Sminchisescu}}}
\bibcite{Comaniciu:PAMI02}{{8}{2002}{{Comaniciu and Meer}}{{}}}
\bibcite{PASCAL:VOC:2012}{{9}{2012}{{Everingham et~al.}}{{Everingham, Van~Gool, Williams, Winn, and Zisserman}}}
\bibcite{Finley:ICML08}{{10}{2008}{{Finley and Joachims}}{{}}}
\bibcite{Freedman:CVPR05}{{11}{2005}{{Freedman and Drineas}}{{}}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces  Example segmentations produced by our Weizmann Horse experiments. Shown are: (a) the image, (b) baseline foreground mask, (c) baseline model foreground overlay, (d) higher-order model foreground mask, and (e) higher-order model foreground overlay.\relax }}{11}{figure.caption.10}}
\newlabel{fig:weizmann_results}{{9}{11}{Example segmentations produced by our Weizmann Horse experiments. Shown are: (a) the image, (b) baseline foreground mask, (c) baseline model foreground overlay, (d) higher-order model foreground mask, and (e) higher-order model foreground overlay.\relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Discussion}{11}{section.6}}
\newlabel{sec:discussion}{{6}{11}{Discussion}{section.6}{}}
\bibcite{Gould:ICML2011}{{12}{2011}{{Gould}}{{}}}
\bibcite{Hammer:1965}{{13}{1965}{{Hammer}}{{}}}
\bibcite{Ishikawa:PAMI03}{{14}{2003}{{Ishikawa}}{{}}}
\bibcite{Ishikawa:CVPR09}{{15}{2009}{{Ishikawa}}{{}}}
\bibcite{Joachims:ML09}{{16}{2009}{{Joachims et~al.}}{{Joachims, Finley, and Yu}}}
\bibcite{Kohli:CVPR10}{{17}{2010}{{Kohli and Kumar}}{{}}}
\bibcite{Kohli:PAMI07}{{18}{2007}{{Kohli and Torr}}{{}}}
\bibcite{Kohli:CVPR07}{{19}{2007}{{Kohli et~al.}}{{Kohli, Kumar, and Torr}}}
\bibcite{Kohli:TR08}{{20}{2008}{{Kohli et~al.}}{{Kohli, Ladicky, and Torr}}}
\bibcite{Koller:2009}{{21}{2009}{{Koller and Friedman}}{{}}}
\bibcite{Kolmogorov:DAM12}{{22}{2012}{{Kolmogorov}}{{}}}
\bibcite{Kolmogorov:PAMI04}{{23}{2004}{{Kolmogorov and Zabih}}{{}}}
\bibcite{Komodakis:CVPR2011}{{24}{2011}{{Komodakis}}{{}}}
\bibcite{Ladicky:ICCV09}{{25}{2009}{{Ladicky et~al.}}{{Ladicky, Russell, Kohli, and Torr}}}
\bibcite{Lempitsky:ICCV09}{{26}{2009}{{Lempitsky et~al.}}{{Lempitsky, Kohli, Rother, and Sharp}}}
\bibcite{Nowozin:CVPR09}{{27}{2009}{{Nowozin and Lampert}}{{}}}
\bibcite{Nowozin:2011}{{28}{2011}{{Nowozin and Lampert}}{{}}}
\bibcite{Orlin:MP2009}{{29}{2009}{{Orlin}}{{}}}
\bibcite{Park:ECCV2012}{{30}{2012}{{Park and Gould}}{{}}}
\bibcite{Pletscher:AISTATS12}{{31}{2012}{{Pletscher and Kohli}}{{}}}
\bibcite{Rother:SIGGRAPH04}{{32}{2004}{{Rother et~al.}}{{Rother, Kolmogorov, and Blake}}}
\bibcite{Rother:CVPR09}{{33}{2009}{{Rother et~al.}}{{Rother, Kohli, Feng, and Jia}}}
\bibcite{Shotton:ECCV06}{{34}{2006}{{Shotton et~al.}}{{Shotton, Winn, Rother, and Criminisi}}}
\bibcite{Szummer:ECCV08}{{35}{2008}{{Szummer et~al.}}{{Szummer, Kohli, and Hoiem}}}
\bibcite{Taskar:ICML05}{{36}{2005}{{Taskar et~al.}}{{Taskar, Chatalbashev, Koller, and Guestrin}}}
\bibcite{Tsochantaridis:ICML04}{{37}{2004}{{Tsochantaridis et~al.}}{{Tsochantaridis, Hofmann, Joachims, and Altun}}}
\bibcite{Tsochantaridis:JMLR05}{{38}{2005}{{Tsochantaridis et~al.}}{{Tsochantaridis, Joachims, Hofmann, and Altun}}}
\bibcite{Yu:ICML09}{{39}{2009}{{Yu and Joachims}}{{}}}
\@writefile{toc}{\contentsline {section}{Biographies}{13}{IEEEbiography.0}}
\@writefile{toc}{\contentsline {subsection}{Stephen Gould}{13}{IEEEbiography.1}}
\citation{Tsochantaridis:JMLR05}
\citation{Tsochantaridis:JMLR05}
\citation{Tsochantaridis:JMLR05}
\@writefile{toc}{\contentsline {section}{Appendix}{14}{section*.13}}
\newlabel{eqn:lagrangian}{{20}{14}{\appendixname }{equation.Appendix.A.20}{}}
\newlabel{eqn:lagrangian2}{{21}{14}{\appendixname }{equation.Appendix.A.21}{}}
\newlabel{eqn:lagrangian3}{{23}{14}{\appendixname }{equation.Appendix.A.23}{}}
\newlabel{eqn:lagrangian_matrix}{{24}{14}{\appendixname }{equation.Appendix.A.24}{}}
